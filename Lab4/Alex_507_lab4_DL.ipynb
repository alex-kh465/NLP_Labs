{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ഭൗതികപ്രപഞ്ചത്തെ മൊത്തത്തിൽ സൂചിപ്പിക്കുന്ന പദ...</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>ഭതകപരപഞചതത മതതതതൽ സചപപകകനന പദമണ പരകത ജർമൻ natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ഭൗതികപ്രതിഭാസങ്ങളും ജീവനും പ്രകൃതിയുടെ ഘടകങ്ങള...</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>ഭതകപരതഭസങങള ജവന പരകതയട ഘടകങങളണ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>മനുഷ്യനിർമിതമായ വസ്തുക്കളെ പ്രകൃതിയുടെ ഭാഗമായി...</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>മനഷയനർമതമയ വസതകകള പരകതയട ഭഗമയ കണകകകകറലല</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>അവയെ കൃത്രിമം എന്ന് വിശേഷിപ്പിക്കുന്നുഅഭിപ്രായ...</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>അവയ കതരമ എനന വശഷപപകകനനഅഭപരയസവതനതരയ ഇഗലഷ പദമയ n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>പ്രകൃതി എന്ന പദം പ്രപഞ്ചത്തെയും അതിലെ സമസ്ത പ്...</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>പരകത എനന പദ പരപഞചതതയ അതല സമസത പരതഭസങങളയ ഉൾകകളളനന</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Language  \\\n",
       "0  ഭൗതികപ്രപഞ്ചത്തെ മൊത്തത്തിൽ സൂചിപ്പിക്കുന്ന പദ...  Malayalam   \n",
       "1  ഭൗതികപ്രതിഭാസങ്ങളും ജീവനും പ്രകൃതിയുടെ ഘടകങ്ങള...  Malayalam   \n",
       "2  മനുഷ്യനിർമിതമായ വസ്തുക്കളെ പ്രകൃതിയുടെ ഭാഗമായി...  Malayalam   \n",
       "3  അവയെ കൃത്രിമം എന്ന് വിശേഷിപ്പിക്കുന്നുഅഭിപ്രായ...  Malayalam   \n",
       "4  പ്രകൃതി എന്ന പദം പ്രപഞ്ചത്തെയും അതിലെ സമസ്ത പ്...  Malayalam   \n",
       "\n",
       "                                          clean_text  \n",
       "0  ഭതകപരപഞചതത മതതതതൽ സചപപകകനന പദമണ പരകത ജർമൻ natu...  \n",
       "1                     ഭതകപരതഭസങങള ജവന പരകതയട ഘടകങങളണ  \n",
       "2            മനഷയനർമതമയ വസതകകള പരകതയട ഭഗമയ കണകകകകറലല  \n",
       "3  അവയ കതരമ എനന വശഷപപകകനനഅഭപരയസവതനതരയ ഇഗലഷ പദമയ n...  \n",
       "4   പരകത എനന പദ പരപഞചതതയ അതല സമസത പരതഭസങങളയ ഉൾകകളളനന  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "df[\"clean_text\"] = df[\"Text\"].apply(clean_text)\n",
    "\n",
    "# Check dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sequence: [2900 2901 1700 1184 1701 2902 2903 1185  195 1186 2904 2905 2906 2907\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "vocab_size = 20000  # Size of the vocabulary\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"clean_text\"])\n",
    "\n",
    "# Convert text to sequences\n",
    "X_seq = tokenizer.texts_to_sequences(df[\"clean_text\"])\n",
    "X_padded = pad_sequences(X_seq, maxlen=150, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "print(\"Example sequence:\", X_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'Hindi': 0, 'Kannada': 1, 'Malayalam': 2, 'Tamil': 3}\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"Language\"])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_categorical = tf.keras.utils.to_categorical(df[\"label\"], num_classes)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Label mapping:\", dict(zip(label_encoder.classes_, range(num_classes))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 150, 256)          5120000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 150, 256)         394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 150, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 128)              164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,687,108\n",
      "Trainable params: 5,687,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=256, input_length=150),  # Larger embedding size\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),  # BiLSTM for bidirectional context\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(64)),  # Another BiLSTM layer\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation=\"softmax\")  # Multi-class classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",   # Track validation loss\n",
    "    patience=3,           # Stop training if val_loss doesn't improve for 3 epochs\n",
    "    restore_best_weights=True,  # Restore best model weights\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 21s 553ms/step - loss: 5.3840e-04 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9632\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 3.9877e-04 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9632\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 20s 534ms/step - loss: 2.8248e-04 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9599\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 2.0369e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 1.\n",
      "38/38 [==============================] - 20s 526ms/step - loss: 2.0369e-04 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9666\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1093 - accuracy: 0.9632\n",
      "Test Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
