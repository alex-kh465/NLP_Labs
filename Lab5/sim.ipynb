{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.6029748160380572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "docs = [\"Text of first document.\", \"Text of second document.\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "cos_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "print(\"Cosine Similarity:\", cos_sim[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.6\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(doc1, doc2):\n",
    "    words_doc1 = set(doc1.lower().split())\n",
    "    words_doc2 = set(doc2.lower().split())\n",
    "    intersection = len(words_doc1.intersection(words_doc2))\n",
    "    union = len(words_doc1.union(words_doc2))\n",
    "    return intersection / union\n",
    "\n",
    "doc1 = \"Text of first document.\"\n",
    "doc2 = \"Text of second document.\"\n",
    "jac_sim = jaccard_similarity(doc1, doc2)\n",
    "print(\"Jaccard Similarity:\", jac_sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare and Analyze\n",
    "\n",
    "    Cosine Similarity works well for longer texts where word frequency matters.\n",
    "\n",
    "    Jaccard Similarity is more effective for short texts or phrase matching.\n",
    "\n",
    "    Cosine Similarity captures context better with TF-IDF, while Jaccard is a simple word overlap measure.\n",
    "\n",
    "    If using Word Mover's Distance (WMD), it would capture semantic meaning but is computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Discuss NLP Applications\n",
    "\n",
    "    Information Retrieval: Cosine Similarity is widely used in search engines.\n",
    "\n",
    "    Text Clustering: Jaccard Similarity can help in grouping similar documents.\n",
    "\n",
    "    Plagiarism Detection: A mix of both can provide a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# long paragraphs\n",
    "doc1 = \"\"\"Natural Language Processing (NLP) is a subfield of artificial intelligence that deals with \n",
    "the interaction between computers and human language. It enables computers to understand, interpret, \n",
    "and generate human language in a valuable way. NLP techniques are used in applications such as chatbots, \n",
    "text summarization, sentiment analysis, and machine translation.\"\"\"\n",
    "\n",
    "doc2 = \"\"\"NLP, a branch of AI, focuses on making computers understand and process human language. \n",
    "It is widely applied in fields like automatic translation, sentiment detection, chatbot development, \n",
    "and text summarization. The advancements in deep learning have significantly improved NLP models, \n",
    "enhancing their ability to process and generate human-like text.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### **Preprocessing**\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Removing punctuation\n",
    "    return text\n",
    "\n",
    "doc1_clean = preprocess_text(doc1)\n",
    "doc2_clean = preprocess_text(doc2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity (TF-IDF): 0.4005821117789597\n"
     ]
    }
   ],
   "source": [
    "### **1. Cosine Similarity using TF-IDF**\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([doc1_clean, doc2_clean])\n",
    "cos_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "print(\"Cosine Similarity (TF-IDF):\", cos_sim[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.2727272727272727\n"
     ]
    }
   ],
   "source": [
    "### **2. Jaccard Similarity using word sets**\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "    words_doc1 = set(doc1.split())\n",
    "    words_doc2 = set(doc2.split())\n",
    "    intersection = len(words_doc1.intersection(words_doc2))\n",
    "    union = len(words_doc1.union(words_doc2))\n",
    "    return intersection / union\n",
    "\n",
    "jac_sim = jaccard_similarity(doc1_clean, doc2_clean)\n",
    "print(\"Jaccard Similarity:\", jac_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
