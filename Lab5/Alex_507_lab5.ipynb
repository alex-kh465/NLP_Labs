{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aspire_Lays\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.2090\n",
      "Jaccard Similarity: 0.1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#question 1\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Sample documents\n",
    "doc1 = \"Natural language processing helps computers understand human language.\"\n",
    "doc2 = \"NLP enables machines to process and analyze human language effectively.\"\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
    "    tokens = text.split()  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Preprocess the documents\n",
    "doc1_clean = preprocess(doc1)\n",
    "doc2_clean = preprocess(doc2)\n",
    "\n",
    "# 1. **Cosine Similarity using TF-IDF**\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([doc1_clean, doc2_clean])\n",
    "cos_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "\n",
    "# 2. **Jaccard Similarity**\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "    set1, set2 = set(doc1.split()), set(doc2.split())\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "jaccard_sim = jaccard_similarity(doc1_clean, doc2_clean)\n",
    "\n",
    "# **Results Comparison**\n",
    "print(f\"Cosine Similarity: {cos_sim:.4f}\")\n",
    "print(f\"Jaccard Similarity: {jaccard_sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Polarity  Subjectivity\n",
      "0  I absolutely love this product! It works like ...     0.625         0.600\n",
      "1  The movie was okay, but it could have been bet...     0.500         0.500\n",
      "2  I had a terrible experience with the customer ...    -1.000         1.000\n",
      "3           This is the best phone I have ever used!     1.000         0.300\n",
      "4  The weather is neither too hot nor too cold to...    -0.175         0.925\n"
     ]
    }
   ],
   "source": [
    "#question 2\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "# Sample text data\n",
    "texts = [\n",
    "    \"I absolutely love this product! It works like a charm.\",\n",
    "    \"The movie was okay, but it could have been better.\",\n",
    "    \"I had a terrible experience with the customer service.\",\n",
    "    \"This is the best phone I have ever used!\",\n",
    "    \"The weather is neither too hot nor too cold today.\"\n",
    "]\n",
    "\n",
    "# Function to analyze sentiment\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity  # Range: -1 (negative) to +1 (positive)\n",
    "    subjectivity = blob.sentiment.subjectivity  # Range: 0 (objective) to 1 (subjective)\n",
    "    return polarity, subjectivity\n",
    "\n",
    "# Apply sentiment analysis to all texts\n",
    "results = [analyze_sentiment(text) for text in texts]\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame(texts, columns=[\"Text\"])\n",
    "df[\"Polarity\"] = [r[0] for r in results]\n",
    "df[\"Subjectivity\"] = [r[1] for r in results]\n",
    "\n",
    "# Display results\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aspire_Lays\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#question 3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset (label: 1 = positive, 0 = negative)\n",
    "# data = {\n",
    "#     \"text\": [\n",
    "#         \"I love this movie, it was amazing!\",\n",
    "#         \"The food was absolutely terrible.\",\n",
    "#         \"I enjoyed the performance a lot.\",\n",
    "#         \"The service was very bad, never coming again.\",\n",
    "#         \"What a fantastic experience, totally worth it!\",\n",
    "#         \"Horrible customer service, very disappointed.\",\n",
    "#         \"I am happy with the product.\",\n",
    "#         \"This is the worst experience I’ve had.\",\n",
    "#     ],\n",
    "#     \"label\": [1, 0, 1, 0, 1, 0, 1, 0],\n",
    "# }\n",
    "\n",
    "df_org = pd.read_csv(\"train.csv\",encoding=\"latin1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>31072940</td>\n",
       "      <td>227540.0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Greece</td>\n",
       "      <td>10423054</td>\n",
       "      <td>128900.0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>112523</td>\n",
       "      <td>340.0</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>17915568</td>\n",
       "      <td>107160.0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>13132795</td>\n",
       "      <td>246000.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "      Time of Tweet Age of User      Country  Population -2020  \\\n",
       "0           morning        0-20  Afghanistan          38928346   \n",
       "1              noon       21-30      Albania           2877797   \n",
       "2             night       31-45      Algeria          43851044   \n",
       "3           morning       46-60      Andorra             77265   \n",
       "4              noon       60-70       Angola          32866272   \n",
       "...             ...         ...          ...               ...   \n",
       "27476         night       31-45        Ghana          31072940   \n",
       "27477       morning       46-60       Greece          10423054   \n",
       "27478          noon       60-70      Grenada            112523   \n",
       "27479         night      70-100    Guatemala          17915568   \n",
       "27480       morning        0-20       Guinea          13132795   \n",
       "\n",
       "       Land Area (Km²)  Density (P/Km²)  \n",
       "0             652860.0               60  \n",
       "1              27400.0              105  \n",
       "2            2381740.0               18  \n",
       "3                470.0              164  \n",
       "4            1246700.0               26  \n",
       "...                ...              ...  \n",
       "27476         227540.0              137  \n",
       "27477         128900.0               81  \n",
       "27478            340.0              331  \n",
       "27479         107160.0              167  \n",
       "27480         246000.0               53  \n",
       "\n",
       "[27481 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           selected_text sentiment\n",
       "0                    I`d have responded, if I were going   neutral\n",
       "1                                               Sooo SAD  negative\n",
       "2                                            bullying me  negative\n",
       "3                                         leave me alone  negative\n",
       "4                                          Sons of ****,  negative\n",
       "...                                                  ...       ...\n",
       "27476                                             d lost  negative\n",
       "27477                                      , don`t force  negative\n",
       "27478                          Yay good for both of you.  positive\n",
       "27479                         But it was worth it  ****.  positive\n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral\n",
       "\n",
       "[27481 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_org[[\"selected_text\",\"sentiment\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aspire_Lays\\AppData\\Local\\Temp\\ipykernel_1696\\1458995952.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"sentiment\"] = encoder.fit_transform(df[\"sentiment\"])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df[\"sentiment\"] = encoder.fit_transform(df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>d lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>, don`t force</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           selected_text  sentiment\n",
       "0                    I`d have responded, if I were going          1\n",
       "1                                               Sooo SAD          0\n",
       "2                                            bullying me          0\n",
       "3                                         leave me alone          0\n",
       "4                                          Sons of ****,          0\n",
       "...                                                  ...        ...\n",
       "27476                                             d lost          0\n",
       "27477                                      , don`t force          0\n",
       "27478                          Yay good for both of you.          2\n",
       "27479                         But it was worth it  ****.          2\n",
       "27480  All this flirting going on - The ATG smiles. Y...          1\n",
       "\n",
       "[27481 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aspire_Lays\\AppData\\Local\\Temp\\ipykernel_1696\\3868434662.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"selected_text\"] = df[\"selected_text\"].astype(str)\n",
      "C:\\Users\\Aspire_Lays\\AppData\\Local\\Temp\\ipykernel_1696\\3868434662.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"clean_text\"] = df[\"selected_text\"].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
    "    tokens = text.split()  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Convert NaN/float values to empty strings before preprocessing\n",
    "df[\"selected_text\"] = df[\"selected_text\"].astype(str)\n",
    "\n",
    "# Apply preprocessing\n",
    "df[\"clean_text\"] = df[\"selected_text\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"clean_text\"], df[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# **Bag of Words (BoW)**\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# **TF-IDF**\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naïve Bayes (BoW) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73      1562\n",
      "           1       0.69      0.90      0.78      2230\n",
      "           2       0.86      0.76      0.81      1705\n",
      "\n",
      "    accuracy                           0.78      5497\n",
      "   macro avg       0.81      0.76      0.77      5497\n",
      "weighted avg       0.80      0.78      0.78      5497\n",
      "\n",
      "0.7769692559577952\n",
      "Multinomial Naïve Bayes (TF-IDF) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72      1562\n",
      "           1       0.69      0.93      0.79      2230\n",
      "           2       0.88      0.75      0.81      1705\n",
      "\n",
      "    accuracy                           0.78      5497\n",
      "   macro avg       0.82      0.76      0.77      5497\n",
      "weighted avg       0.81      0.78      0.78      5497\n",
      "\n",
      "0.7796980171002365\n"
     ]
    }
   ],
   "source": [
    "# Train Multinomial Naïve Bayes with BoW\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow = nb_bow.predict(X_test_bow)\n",
    "\n",
    "# Train Multinomial Naïve Bayes with TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# **Evaluate Models**\n",
    "print(\"Multinomial Naïve Bayes (BoW) Performance:\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "print(accuracy_score(y_test, y_pred_bow))\n",
    "\n",
    "print(\"Multinomial Naïve Bayes (TF-IDF) Performance:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "print(accuracy_score(y_test, y_pred_tfidf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
